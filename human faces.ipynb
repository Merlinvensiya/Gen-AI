{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAQ+XNMTF7VLGcKCxBOD5J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Merlinvensiya/Gen-AI/blob/main/human%20faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uB8_6oM8wN9t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (_, _) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDVg2Nepzrz_",
        "outputId": "2fd43ba0-7b73-472e-cb88-3dddc7cdc313"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtEyPSP8z4Ig",
        "outputId": "05160703-32f3-4ccd-8660-34e87cafbb98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "28 * 28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb8LnjsOz78D",
        "outputId": "79c2a6bd-cfb8-447a-928a-c8cd7980c8d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrpr3hO0z_N4",
        "outputId": "a96e0279-7f62-491b-8438-0d96ddce5d0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')"
      ],
      "metadata": {
        "id": "SSWif9FF0GIh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqhpAbX90KY-",
        "outputId": "16a8f980-4c2f-4936-8193-9612a8ae3c0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].min(), X_train[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3il1eWh40NcU",
        "outputId": "35f3d4a3-d34b-4843-9a67-99f838064e5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 255.0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = (X_train - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "vGHMJudo0QcN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].min(), X_train[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VL49vH90ULM",
        "outputId": "337eb093-ba74-4946-8ac2-f1c32d7c96f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, cv2\n",
        "import seaborn as sns\n",
        "\n",
        "import os, shutil\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "3jOoURjb0YsA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(src_dir=\"\", image_size=224):\n",
        "    img_data = glob.glob(src_dir + \"/*\")\n",
        "    X = []\n",
        "    for img_path in tqdm(img_data):\n",
        "        try:\n",
        "            img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (image_size, image_size), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            X.append(img)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "#         break\n",
        "\n",
        "    X = np.array(X)\n",
        "\n",
        "    print(X.shape)\n",
        "    return X"
      ],
      "metadata": {
        "id": "jbD3aZNG1gWv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 256\n",
        "X_train = load_data(src_dir=\"/kaggle/input/face-data/FaceData/\", image_size=image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj32pWzg1lWO",
        "outputId": "9da8b9c5-5825-40e4-9941-707f58c1eb84"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images, figsize=(20, 4)):\n",
        "    num_images = len(images)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=figsize)\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2IQ-pOy31pP0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_train) > 0:\n",
        "    indices = np.random.randint(0, len(X_train), size=10)\n",
        "    sample_images = [X_train[ind] for ind in indices]\n",
        "\n",
        "    plot_images(sample_images)\n",
        "else:\n",
        "    print(\"X_train is empty. Cannot generate random indices.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KC6rDKA2Sx9",
        "outputId": "119fae66-a808-4da2-f92d-6cdb1e3d6218"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train is empty. Cannot generate random indices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(image_size, image_size, 3)):\n",
        "    model = Sequential()\n",
        "    # normal\n",
        "    model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "\n",
        "    # classifier\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "vpvJi5b2106u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    # foundation for 4x4 image\n",
        "    n_nodes = 192 * 4 * 4\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((4, 4, 192)))\n",
        "    # upsample to 8x8\n",
        "    model.add(Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 16x16\n",
        "    model.add(Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 32x32\n",
        "    model.add(Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 64x64\n",
        "    model.add(Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 128x128\n",
        "    model.add(Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 256x256\n",
        "    model.add(Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Conv2D(3, (3, 3), activation='tanh', padding='same'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "LlHjJjJ92kqK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_gan(g_model, d_model):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(g_model)\n",
        "    # add the discriminator\n",
        "    model.add(d_model)\n",
        "    # compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model"
      ],
      "metadata": {
        "id": "XP4dfmE02pPu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_real_samples(X_train):\n",
        "    # load cifar10 dataset\n",
        "    # (trainX, _), (_, _) = load_data()\n",
        "    # convert from unsigned ints to floats\n",
        "    X = X_train.astype('float32')\n",
        "    # scale from [0,255] to [-1,1]\n",
        "    X = (X - 127.5) / 127.5\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "chF1z1Pp2tkd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "    # choose random instances\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = ones((n_samples, 1))\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "z7yMqzhn2yGT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "\n",
        "    return x_input"
      ],
      "metadata": {
        "id": "ZuUzVIp921yA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    X = g_model.predict(x_input)\n",
        "    # create 'fake' class labels (0)\n",
        "    y = zeros((n_samples, 1))\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "X2embVlG25Ph"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plot(examples, epoch, n=7):\n",
        "    # scale from [-1,1] to [0,1]\n",
        "    examples = (examples + 1) / 2.0\n",
        "    # plot images\n",
        "    for i in range(n * n):\n",
        "        # define subplot\n",
        "        plt.subplot(n, n, 1 + i)\n",
        "        # turn off axis\n",
        "        plt.axis('off')\n",
        "        # plot raw pixel data\n",
        "        plt.imshow(examples[i])\n",
        "        # save plot to file\n",
        "        filename = './DCGAN_models/generated_plot_e%03d.png' % (epoch+1)\n",
        "        plt.savefig(filename)\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "7oEzjrBG29S5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
        "    # prepare real samples\n",
        "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "    # evaluate discriminator on real examples\n",
        "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "    # prepare fake examples\n",
        "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "    # evaluate discriminator on fake examples\n",
        "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "    # summarize discriminator performance\n",
        "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "    # save plot\n",
        "    save_plot(x_fake, epoch)\n",
        "    # save the generator model tile file\n",
        "    filename = './DCGAN_models/generator_model_%03d.h5' % (epoch+1)\n",
        "    g_model.save(filename)"
      ],
      "metadata": {
        "id": "jwEHqQPT3Amm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=128):\n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_epochs):\n",
        "        # enumerate batches over the training set\n",
        "        for j in range(bat_per_epo):\n",
        "            # get randomly selected 'real' samples\n",
        "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "            # update discriminator model weights\n",
        "            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "            # generate 'fake' examples\n",
        "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            # update discriminator model weights\n",
        "            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "            # prepare points in latent space as input for the generator\n",
        "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "            # create inverted labels for the fake samples\n",
        "            y_gan = ones((n_batch, 1))\n",
        "            # update the generator via the discriminator's error\n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "            # summarize loss on this batch\n",
        "            print('> Epoch:%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "            (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "        # evaluate the model performance, sometimes\n",
        "        if (i+1) % 5 == 0:\n",
        "            summarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "uezaBoZ43FLR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "d_model.summary()\n",
        "\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "g_model.summary()\n",
        "\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "gan_model.summary()\n",
        "\n",
        "# load image data\n",
        "# dataset = load_real_samples()\n",
        "dataset = load_real_samples(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMaTqaIx3K7P",
        "outputId": "102dcba5-e34f-49ee-a368-f787f5a79ba8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 256, 256, 64)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 262144)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 262144)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 262145    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 780545 (2.98 MB)\n",
            "Trainable params: 780545 (2.98 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 3072)              310272    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 3072)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 192)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 192)         590016    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 192)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 192)       590016    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 192)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 192)       590016    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 192)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 64, 64, 192)       590016    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 64, 64, 192)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2D  (None, 128, 128, 192)     590016    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 128, 128, 192)     0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2D  (None, 256, 256, 192)     590016    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 256, 256, 192)     0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 256, 3)       5187      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3855555 (14.71 MB)\n",
            "Trainable params: 3855555 (14.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 256, 256, 3)       3855555   \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 1)                 780545    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4636100 (17.69 MB)\n",
            "Trainable params: 3855555 (14.71 MB)\n",
            "Non-trainable params: 780545 (2.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input"
      ],
      "metadata": {
        "id": "OW8YkSx53yXh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plot(examples, n_cols=10, n_rows=6):\n",
        "    # Set up the figure with the specified number of columns and rows\n",
        "    # fig, axs = pyplot.subplots(n_rows, n_cols, figsize=(8, 3))\n",
        "    fig, axs = pyplot.subplots(n_rows, n_cols, figsize=(15, 8))\n",
        "\n",
        "    # Flatten the axes array for easy iteration\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    # Plot images\n",
        "    for i in range(n_cols * n_rows):\n",
        "        # Turn off axis\n",
        "        axs[i].axis('off')\n",
        "        # Plot raw pixel data\n",
        "        axs[i].imshow(examples[i, :, :])\n",
        "\n",
        "    # Adjust layout for better spacing\n",
        "    pyplot.tight_layout()\n",
        "    # Save the plot to a file (optional)\n",
        "    pyplot.savefig('generated_images_plot.png')\n",
        "    # Show the plot (optional)\n",
        "    pyplot.show()"
      ],
      "metadata": {
        "id": "EG_-IGln30vn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./DCGAN_models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYI8S24t4mS_",
        "outputId": "ada9469f-7bcc-4949-b7bb-1dba669b782b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './DCGAN_models/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgOXWLZ84qT6",
        "outputId": "7a0506bb-1d70-4c82-a8dd-21bb7100d12c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "1Fw80uTP4tiX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = './DCGAN_models/generator_model_200.h5'"
      ],
      "metadata": {
        "id": "kVVxFExq41AY"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}